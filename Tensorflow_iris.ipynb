{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the method from the Deep learning class to process the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "train_data= pd.read_csv(\"iris_training.csv\")\n",
    "test_data= pd.read_csv(\"iris_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sepal length</th>\n",
       "      <td>6.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal width</th>\n",
       "      <td>2.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal length</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal width</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0    1    2    3    4    5    6    7    8    9   ...   110  111  \\\n",
       "sepal length  6.4  5.0  4.9  4.9  5.7  4.4  5.4  6.9  6.7  5.1 ...   6.3  5.7   \n",
       "sepal width   2.8  2.3  2.5  3.1  3.8  3.2  3.4  3.1  3.1  3.7 ...   2.7  2.8   \n",
       "petal length  5.6  3.3  4.5  1.5  1.7  1.3  1.5  5.1  4.4  1.5 ...   4.9  4.1   \n",
       "petal width   2.2  1.0  1.7  0.1  0.3  0.2  0.4  2.3  1.4  0.4 ...   1.8  1.3   \n",
       "class         2.0  1.0  2.0  0.0  0.0  0.0  0.0  2.0  1.0  0.0 ...   2.0  1.0   \n",
       "\n",
       "              112  113  114  115  116  117  118  119  \n",
       "sepal length  5.0  6.3  5.0  5.5  5.7  4.4  4.8  5.5  \n",
       "sepal width   3.0  3.3  3.5  2.6  3.0  2.9  3.0  2.4  \n",
       "petal length  1.6  6.0  1.6  4.4  4.2  1.4  1.4  3.7  \n",
       "petal width   0.2  2.5  0.6  1.2  1.2  0.2  0.1  1.0  \n",
       "class         0.0  2.0  0.0  1.0  1.0  0.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transposing the data to have dimensions (features, m)\n",
    "train_df= train_data.transpose()\n",
    "test_df= test_data.transpose()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the data into features and labels\n",
    "X_train= train_df.drop([\"class\"])\n",
    "y_train= train_data[\"class\"]\n",
    "X_test= test_df.drop([\"class\"])\n",
    "y_test= test_data[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting X into numpy.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= X_train.values\n",
    "X_test= X_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding of y_train and y_test\n",
    "Many times in deep learning you will have a y vector with numbers ranging from 0 to C-1, where C is the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C):\n",
    "    # Create a tf.constant equal to C (depth)\n",
    "    C = tf.constant(C, name=\"C\")\n",
    "\n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(labels, depth=C, axis=0)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train= one_hot_matrix(y_train, C=3)\n",
    "Y_test= one_hot_matrix(y_test, C=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Creating placeholders for X and Y\n",
    "This will allow us to later pass our training data in when we run our session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    #n_x -- scalar, number of features\n",
    "    #n_y -- scalar, number of classes\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, [n_x, None])\n",
    "    Y = tf.placeholder(tf.float32, [n_y, None])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Initializing the parameters/weigths W and b\n",
    "We are going to use Xavier Initialization for weights and Zero Initialization for biases. We're going to build a 3-layer NN with 4 units in the hidden layers and 3 units in the output layer (since we have 3 different classes). The shapes are therefore the following:\n",
    "- W1 and W2: [4,4]\n",
    "- b1 and b2: [4,1]\n",
    "- W3: [3,4]\n",
    "- b3: [3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \n",
    "    tf.set_random_seed(1)    \n",
    "    W1 = tf.get_variable(\"W1\", [4,4], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [4,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [4,4], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [4,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [3,4], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [3,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Defining mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    np.random.seed(seed)\n",
    "    m = X.shape[1]\n",
    "    mini_batches = []\n",
    "        \n",
    "    # shuffling (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation]  #.reshape((3,m))\n",
    "\n",
    "    # partitioning (minus the end case)\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size)\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k*mini_batch_size : (k+1)*mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k*mini_batch_size : (k+1)*mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches*mini_batch_size : m+1]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches*mini_batch_size : m+1]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Implementing forward prop\n",
    "Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    # Retrieving parameters \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    # implementing forward prop\n",
    "    Z1 = tf.add( tf.matmul(W1, X), b1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    Z2 = tf.add( tf.matmul(W2, A1), b2)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    Z3 = tf.add( tf.matmul(W3, A2), b3)\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Computing the cost\n",
    "\n",
    "It is important to know that the \"logits\" and \"labels\" inputs of tf.nn.softmax_cross_entropy_with_logits are expected to be of shape (number of examples, num_classes). We therefore need to **transpose Z3 and Y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    # transposing Z3 and Y to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Backprop and parameter updates\n",
    "All the backpropagation and the parameters update is taken care of in 1 line of code thanks to Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.01,\n",
    "          num_epochs = 1000, minibatch_size = 32, print_cost = True):\n",
    " \n",
    "    ops.reset_default_graph()\n",
    "    tf.set_random_seed(1)\n",
    "    seed = 3\n",
    "    (n_x, m) = X_train.shape\n",
    "    n_y = Y_train.shape[0]\n",
    "    costs = []\n",
    "    \n",
    "    # creating placeholders\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    # initializing parameters\n",
    "    parameters = initialize_parameters()\n",
    "\n",
    "    # Forward prop\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    # adding cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # backprop: defining the tensorflow optimizer (AdamOptimizer)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size)\n",
    "            seed = seed+1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # saving the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "\n",
    "        # calculating correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # calculating accuracy on the TEST set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.662236\n",
      "Cost after epoch 100: 0.339344\n",
      "Cost after epoch 200: 0.180884\n",
      "Cost after epoch 300: 0.104010\n",
      "Cost after epoch 400: 0.084618\n",
      "Cost after epoch 500: 0.078849\n",
      "Cost after epoch 600: 0.072751\n",
      "Cost after epoch 700: 0.060619\n",
      "Cost after epoch 800: 0.058437\n",
      "Cost after epoch 900: 0.055720\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c253cefd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.983333\n",
      "Test Accuracy: 0.966667\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
